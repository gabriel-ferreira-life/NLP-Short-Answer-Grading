{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive to access dataset files (train.csv and test.csv)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB0L-_pMOeeP",
        "outputId": "46377039-96b5-4b84-b314-51ed62c71c6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base path to the project folder in Drive (update this as needed for your Drive structure)\n",
        "base_path = \"/content/drive/My Drive/Colab Notebooks/COMS5790/Final Project/\""
      ],
      "metadata": {
        "id": "s0OVvD-XOebY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFvUvy2iOWKK",
        "outputId": "1a58c052-682a-4d3b-dbfe-5fff21b15881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Experiment    Topic   ID                        Question  \\\n",
            "0           1  Physics  104  How thin can a fiber optic be?   \n",
            "1           1  Physics  126  How thin can a fiber optic be?   \n",
            "2           1  Physics  130  How thin can a fiber optic be?   \n",
            "3           1  Physics  131  How thin can a fiber optic be?   \n",
            "4           1  Physics  156  How thin can a fiber optic be?   \n",
            "\n",
            "                                 Response            CorrectAnswer  label  \n",
            "0                        a strand of hair  As thin as a human hair      1  \n",
            "1                  Really thin and small   As thin as a human hair     -1  \n",
            "2                 as thin as a human hair  As thin as a human hair      1  \n",
            "3  Very thin smaller than a pice of hair   As thin as a human hair      1  \n",
            "4     Less than the width of a human hair  As thin as a human hair      1  \n",
            "Test Accuracy: 0.700\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "        Incorrect       0.73      0.95      0.83     16614\n",
            "Partially Correct       0.02      0.17      0.03       320\n",
            "          Correct       1.00      0.41      0.58     13532\n",
            "\n",
            "         accuracy                           0.70     30466\n",
            "        macro avg       0.58      0.51      0.48     30466\n",
            "     weighted avg       0.84      0.70      0.71     30466\n",
            "\n",
            "Confusion Matrix:\n",
            "[[15763   843     8]\n",
            " [  264    56     0]\n",
            " [ 5458  2581  5493]]\n"
          ]
        }
      ],
      "source": [
        "# 2. Load the training and testing datasets using pandas\n",
        "# We assume 'train.csv' and 'test.csv' contain the short answer data with a 'label' column.\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(base_path + \"train.csv\", encoding='latin-1')\n",
        "df_test = pd.read_csv(base_path + \"test.csv\", encoding='latin-1')\n",
        "\n",
        "# Inspect the first few rows to understand the structure (optional)\n",
        "print(df_train.head())  # This will show columns like Question, Response, CorrectAnswer, label, etc.\n",
        "\n",
        "# 3. Define a simple rule-based grading function.\n",
        "# This function will compare the student's response with the correct answer.\n",
        "# It uses keyword overlap:\n",
        "#    - If the response contains ALL keywords from the correct answer, we mark it as Correct.\n",
        "#    - If the response contains SOME (at least ~half) of the keywords, we mark it as Partially Correct.\n",
        "#    - Otherwise, mark the response as Incorrect.\n",
        "import math\n",
        "import string\n",
        "\n",
        "# Prepare a basic list of stopwords (common words to ignore in overlap) to focus on meaningful keywords\n",
        "stopwords = {\"the\", \"a\", \"an\", \"of\", \"to\", \"and\", \"is\", \"are\", \"in\", \"for\", \"on\", \"this\", \"that\", \"it\"}\n",
        "\n",
        "def grade_response(correct_answer: str, student_answer: str) -> int:\n",
        "    \"\"\"\n",
        "    Determine the grade label for a student answer given the correct answer.\n",
        "    Returns 1 for Correct, 0 for Partially Correct, and -1 for Incorrect.\n",
        "    \"\"\"\n",
        "    # Convert both answers to lowercase and remove punctuation for fair comparison\n",
        "    correct = correct_answer.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    response = student_answer.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # Split into individual words\n",
        "    correct_words = [w for w in correct.split() if w not in stopwords]\n",
        "    response_words = [w for w in response.split() if w not in stopwords]\n",
        "\n",
        "    # Use set for unique words to avoid double counting duplicates\n",
        "    correct_keywords = set(correct_words)\n",
        "    response_words_set = set(response_words)\n",
        "\n",
        "    if len(correct_keywords) == 0:\n",
        "        # Edge case: if correct answer has no meaningful keywords (very short or all stopwords),\n",
        "        # handle by simple direct string match as fallback\n",
        "        if response.strip().lower() == correct.strip().lower():\n",
        "            return 1  # if the answers match exactly\n",
        "        else:\n",
        "            return -1\n",
        "\n",
        "    # Count how many of the correct answer's keywords appear in the student response\n",
        "    overlap_count = sum(1 for word in correct_keywords if word in response_words_set)\n",
        "\n",
        "    # Determine thresholds for partial vs correct\n",
        "    total_keywords = len(correct_keywords)\n",
        "    # Threshold for partial credit: at least half of the keywords (rounded up) should match\n",
        "    partial_threshold = math.ceil(total_keywords * 0.5)\n",
        "\n",
        "    # Apply the rules:\n",
        "    if overlap_count == total_keywords:\n",
        "        # Student response contains all keywords from the correct answer\n",
        "        return 1  # Correct\n",
        "    elif overlap_count >= partial_threshold and overlap_count > 0:\n",
        "        # Student response contains a significant portion of the keywords (but not all)\n",
        "        return 0  # Partially Correct\n",
        "    else:\n",
        "        # Student response matches very few or none of the keywords\n",
        "        return -1  # Incorrect\n",
        "\n",
        "# 4. Generate predictions on the test set using the rule-based function\n",
        "y_true = df_test['label'].tolist()        # True labels from the dataset (-1, 0, or 1)\n",
        "y_pred = []                               # This will hold our predicted labels\n",
        "for idx, row in df_test.iterrows():\n",
        "    # For each answer in the test set, apply the grading function\n",
        "    correct_ans = row['CorrectAnswer']\n",
        "    student_ans = row['Response']\n",
        "\n",
        "    # Check if student_ans is a float and represents a missing value (NaN)\n",
        "    if isinstance(student_ans, float) and pd.isna(student_ans):\n",
        "        # Handle missing values - you might assign a default label, skip, or impute\n",
        "        # Here, we'll assign -1 (Incorrect) for missing responses\n",
        "        pred_label = -1\n",
        "    else:\n",
        "        pred_label = grade_response(correct_ans, student_ans)\n",
        "\n",
        "    y_pred.append(pred_label)\n",
        "\n",
        "# 5. Evaluate the model's performance using common metrics: Accuracy, Precision, Recall, F1-score, and Confusion Matrix.\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Map the original labels to 0,1,2 for consistency (Incorrect->0, Partially Correct->1, Correct->2)\n",
        "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
        "y_true_ids = [label_mapping[l] for l in y_true]\n",
        "y_pred_ids = [label_mapping[l] for l in y_pred]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_true_ids, y_pred_ids)\n",
        "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "# Print detailed classification report (precision, recall, F1 for each class)\n",
        "target_names = [\"Incorrect\", \"Partially Correct\", \"Correct\"]\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true_ids, y_pred_ids, target_names=target_names, digits=2, zero_division=0))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true_ids, y_pred_ids))\n"
      ]
    }
  ]
}